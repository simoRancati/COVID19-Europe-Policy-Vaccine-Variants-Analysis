## COVID19-Europe-Policy-Vaccine-Variants-Analysis
This repository contains the code for replicating the analysis presented in the paper titled "A Country-Level Comparative Study on the Impact of Containment Policies, Vaccination Strategies, and Virus Variants during the COVID-19 Pandemic in Europe."

## Requirements and installation

**Dependencies**
**Python** scientific stack: 
1. pandas <code>pip install pandas==1.5.3</code>
2. numpy <code>pip install numpy==1.24.1</code>
3. statistics <code>pip install statistics==1.0.3.5</code>
4. scipy <code>pip install scipy==1.10.1</code>
5. matplotlib <code>pip install matplotlib==3.8.3</code>
6. scikit-learn <code>pip install scikit-learn==1.2.1</code>
7. biopython <code>pip install biopython==1.80</code> 

**R language**:
1. BiocManger <code>install.packages("BiocManager")</code>
2. Biostrings <code>BiocManager::install("Biostrings")</code>
3. stringr <code>install.packages("stringr")</code>
4. vroom <code>install.packages("vroom")</code>
5. Matrix <code>install.packages("Matrix")</code>
6. dplyr <code>install.packages("dplyr")</code>
7. ggplot2 <code>install.packages("ggplot2")</code>
8. lme4 <code>install.packages("lme4")</code>
9. lubridate <code>install.packages("lubridate")</code>
10. mlVAR <code>install.packages("mlVAR")</code>
11. pheatmap <code>install.packages("pheatmap")</code>
12. plm <code>install.packages("plm")</code>
13. plyr <code>install.packages("plyr")</code>
14. pompom <code>install.packages("pompom")</code>
15. psych <code>install.packages("psych")</code>
16. readr <code>install.packages("readr")</code>
17. reshape2 <code>install.packages("reshape2")</code>
18. tidyr <code>install.packages("tidyr")</code>
19. tidyverse <code>install.packages("tidyverse")</code>
20. zoo <code>install.packages("zoo")</code>

Python version <code>[3.8](https://www.python.org/downloads/release/python-390/)</code> and R <code>[4.4.0](https://cran.r-project.org/bin/windows/base/)</code> are required. 

## Data
The <code>Data</code> folder contains the necessary CSV files for the analysis. These Folder include:
1. <code>[Death.csv.zip](Data/Death.csv.zip)</code>: This file contains data on the weekly COVID-19 death counts across various nations.
2. <code>[Hospital.csv.zip](Data/Hospital.csv.zip)</code>: This file includes data on weekly hospitalizations due to COVID-19 in different countries.
3. <code>[Vaccine_EU.csv.zip](Data/Vaccine_EU.csv.zip)</code>: This dataset provides information on COVID-19 vaccinations across different nations.
4. <code>[owid-covid-data.csv.zip](Data/owid-covid-data.csv.zip)</code>: This file contains the weekly stringency index data for various countries, indicating the level of government responses.
5. <code>metadata.csv</code>: To use this file, you must register with the <code>[GISAID](https://gisaid.org/)</code> database and download the corresponding TSV file.

## Preprocessing
The files to create the dataset is <code>[First_Filtration.R](Preprocessing/First_Filtration.R)</code>, <code>[Data_filtration_kmers.py](Preprocessing/Data_Filtration_kmers.py)</code> and <code>[Creating_Dataset.Rmd](Preprocessing/Creating_Dataset.Rmd)</code>

I)<code>[First_Filtration_codeline.R](FeatureExtraction/First_Filtration_codeline.R)</code> serves as the primary tool for processing the <code>[metadataset.tsv](https://gisaid.org/)</code> file obtained from the GISAID website (https://gisaid.org/) along with its corresponding <code>[Spikes.fasta](https://gisaid.org/)</code> file. It filters and restructures the data, outputting two refined files: <code>metadata.csv</code> and <code>spikes.fasta</code>.


Mandatory:


-Spikes.fasta: path where the input fasta file is stored (<code>[GISAID FASTA file](https://gisaid.org/)</code>);

-metadataset.tsv: path where the input metadata (tsv) is stored (<code>[GISAID TSV file](https://gisaid.org/)</code>): Sequences and metadata should be in the same order. All columns are necessary and must be in the same order as in the example file, i.e.: <code> Virus name, Last vaccinated, Passage details/history, Type, Accession ID, Collection date, Location, Additional location information, Sequence length, Host, Patient age, Gender, Clade, Pango lineage, Pango version, Variant, AA Substitutions, Submission date, Is reference?, Is complete?, Is high coverage?, Is low coverage?, N-Content, GC-Content</code>

-spikes.fasta: path where the output fasta file is saved;

-metadata.csv: path where the output csv file is saved.

II)<code>[Data_filtration_kmers.py](Preprocessing/Data_Filtration_kmers.py)</code>acts the second phase in the data processing workflow, building upon the outputs generated by the <code>First_Filtration_codeline.R</code> script. It takes the [metadataset.csv](https://gisaid.org/) and [spikes.fasta](https://gisaid.org/) files as inputs, which are the refined versions of the original datasets.Example: <code>python Data_Filtration_kmers.py -f spikes.fasta -c metadataset.csv -m 1000 -l 30 -p /path/to/save/dataset_interest_2023 </code>


Mandatory:

-f: path where the input fasta file is stored (Example file: <code>[spikes.fasta](data_github/spikes.fasta)</code>);

-c: path where the input metadata (csv) is stored (Example file: <code>[metadataset.csv](data_github/metadataset.csv)</code>). Sequences and metadata should be in the same order. All columns are necessary and must be in the same order as in the example file, i.e.: <code> Virus name, Last vaccinated, Passage details/history, Type, Accession ID, Collection date, Location, Additional location information, Sequence length, Host, Patient age, Gender, Clade, Pango lineage, Pango version, Variant, AA Substitutions, Submission date, Is reference?, Is complete?, Is high coverage?, Is low coverage?, N-Content, GC-Content</code>


Optional:
-n: nation (e.g., "France") (if not specified, all sequences are used) (<code>default: ['/']</code>);

-m: Filter: minimum lenght of the spike sequences (<code>default value: 1000</code>); 

-l: Filter: accepted amino acid distant from lineage median (<code>default value: 30</code>); as in: for each lineage, how the protein length can vary to be accepted?

-p: path to save the outputs.


-Output:

1) Metadata: Metadata of filtered sequences;

III)<code>[Creating_Dataset.Rmd](Preprocessing/Creating_Dataset.Rmd)</code>acts the third phase in the data processing workflow, building upon the outputs generated by the <code>[Data_filtration_kmers.py](Preprocessing/Data_Filtration_kmers.py)</code> script. It takes the <code>[metadataset.csv](data_github/metadataset.csv)</code>, <code>[Death.csv.zip](Data/Death.csv.zip)</code>, <code>[Hospital.csv.zip](Data/Hospital.csv.zip)</code>, <code>[Vaccine_EU.csv.zip](Data/Vaccine_EU.csv.zip)</code>,<code>[owid-covid-data.csv.zip](Data/owid-covid-data.csv.zip)</code> files as inputs to create the final datasets. 


-Output:

1) Datasets: Datasets for each Nation of Interest;
